{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>song</th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ego-remix</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Oh baby, how you doing?\\nYou know I'm gonna cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>then-tell-me</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>playin' everything so easy,\\nit's like you see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>honesty</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>If you search\\nFor tenderness\\nIt isn't hard t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>you-are-my-rock</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>black-culture</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Party the people, the people the party it's po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index             song  year           artist genre  \\\n",
       "0      0        ego-remix  2009  beyonce-knowles   Pop   \n",
       "1      1     then-tell-me  2009  beyonce-knowles   Pop   \n",
       "2      2          honesty  2009  beyonce-knowles   Pop   \n",
       "3      3  you-are-my-rock  2009  beyonce-knowles   Pop   \n",
       "4      4    black-culture  2009  beyonce-knowles   Pop   \n",
       "\n",
       "                                              lyrics  \n",
       "0  Oh baby, how you doing?\\nYou know I'm gonna cu...  \n",
       "1  playin' everything so easy,\\nit's like you see...  \n",
       "2  If you search\\nFor tenderness\\nIt isn't hard t...  \n",
       "3  Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...  \n",
       "4  Party the people, the people the party it's po...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data (if no pickle)\n",
    "df = pd.read_csv('lyrics.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data (if no pickle)\n",
    "def mergeGenre(genre):\n",
    "    if genre == \"Country\" or (genre) == \"Folk\":\n",
    "        return \"Country/Folk\"\n",
    "    if genre == \"Hip-Hop\" or (genre) == \"R&B\":\n",
    "        return \"Hip-Hop/R&B\"\n",
    "    if genre == \"Rock\" or (genre) == \"Metal\":\n",
    "        return \"Rock/Metal\"\n",
    "    return genre\n",
    "    \n",
    "df['lyrics'] = df['lyrics'].apply(lambda l: str(l)\n",
    "                                  .replace('\\n', ' ')\n",
    "                                  .replace('.', '')\n",
    "                                  .replace(',', '')\n",
    "                                  .replace('!', '')\n",
    "                                  .replace('?', '')\n",
    "                                  .lower())\n",
    "\n",
    "df['genre'] = df['genre'].apply(lambda row: mergeGenre(row))\n",
    "df['word_count'] = df['lyrics'].str.split(' ').str.len()\n",
    "df = df[df['word_count'] > 10]\n",
    "df = df[df['genre'] != 'Other']\n",
    "df = df[df['genre'] != 'Not Available']\n",
    "df = df[df['genre'] != 'Indie']\n",
    "df = df[df['song'].str.contains('remix') == False]\n",
    "#df = df[df['genre'] != 'Jazz']\n",
    "#df = df[df['genre'] != 'Electronic']\n",
    "\n",
    "# Sample data (optional)\n",
    "#df = df.sample(frac=0.5, replace=False, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/nickruspantini/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Get polarity scores of lyrics (if no pickle)\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "df['pos_score'] = df['lyrics'].apply(lambda row: sid.polarity_scores(row)['pos'])\n",
    "df['neg_score'] = df['lyrics'].apply(lambda row: sid.polarity_scores(row)['neg'])\n",
    "df['neu_score'] = df['lyrics'].apply(lambda row: sid.polarity_scores(row)['neu'])\n",
    "df['compound_score'] = df['lyrics'].apply(lambda row: sid.polarity_scores(row)['compound'])\n",
    "\n",
    "df.to_pickle(\"./data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nickruspantini/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(\"./data.pkl\")\n",
    "\n",
    "# Get numerical features with Natural Language Toolkit\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "lyrics = df['lyrics']\n",
    "sWords = stopwords.words('english')\n",
    "sWords.extend(('got', 'get', 'gets' 'getting', '2X', '2x', 'x2', 'x3', 'x4', 'x2chorus', 'chorus', 'verse', 'bridge', 'd\\xe3', 'n\\xe3', 'm\\xe3', 'the', 'it', 'is', \"it's\", 'are', 'were', 'a', 'an', 'its', 'of', 'for'))\n",
    "\n",
    "tfidfconverter = TfidfVectorizer(norm='l2', use_idf=True, smooth_idf=True, ngram_range = (1,2), max_features=1000, min_df=3, max_df=0.7, stop_words=sWords)\n",
    "n_features = tfidfconverter.fit_transform(lyrics)\n",
    "df['n_features'] = list(n_features.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top ranking words\n",
    "features = (tfidfconverter.get_feature_names()) \n",
    "sums = n_features.sum(axis = 0) \n",
    "data = [] \n",
    "for col, term in enumerate(features): \n",
    "    data.append( (term, sums[0, col] )) \n",
    "ranking = pd.DataFrame(data, columns = ['term', 'rank']) \n",
    "words = (ranking.sort_values('rank', ascending = False)) \n",
    "print (words.head(10))\n",
    "#print tfidfconverter.get_stop_words()\n",
    "#print tfidfconverter.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X: Bag of words model with polarity scores, word count\n",
    "def f(row):    \n",
    "    np.append(row[5], row[0])\n",
    "    np.append(row[5], row[1])\n",
    "    np.append(row[5], row[2])\n",
    "    np.append(row[5], row[3])\n",
    "    return np.append(row[5], row[4])\n",
    "    return [row[0], row[]]\n",
    "\n",
    "X = np.vstack((df['pos_score'], df['neg_score'], df['neu_score'], df['compound_score'], df['word_count'], df['n_features'])).T\n",
    "X = np.array(map(f, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X: Bag of words model\n",
    "X = n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X: Polarity scores, word count\n",
    "X = df[['pos_score', 'neg_score', 'neu_score', 'compound_score', 'word_count']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test\n",
    "import time\n",
    "startTime = time.time()\n",
    "\n",
    "y = df['genre']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=1)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print \"Score: \", classifier.score(X_test, y_test)\n",
    "endTime = time.time()\n",
    "elapsedTime = endTime - startTime\n",
    "print \"Time: \", elapsedTime\n",
    "\n",
    "preds = classifier.predict(X_test)\n",
    "print(sklearn.metrics.confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "print sklearn.metrics.classification_report(y_test, preds)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
