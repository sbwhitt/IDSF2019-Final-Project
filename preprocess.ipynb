{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessor\n",
    "**Input** : Unprocessed CSV file\n",
    "**Output**: Processed (cleaned) pkl file\n",
    "- 'Instrumental' genres are removed\n",
    "- Remove newlines\n",
    "- Remove songs with no lyrics (nan)\n",
    "- Remove songs with word_count != 1\n",
    "- Lemmatize data\n",
    "- Append data with polarity for sentiment analysis\n",
    "- Remove stop words\n",
    "\n",
    "Check language\n",
    "https://stackoverflow.com/questions/3182268/nltk-and-language-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Preprocessor globals ###\n",
    "\n",
    "# Input\n",
    "INPUT_FILE_PATH = './'\n",
    "INPUT_FILE_NAME = 'lyrics.csv'\n",
    "\n",
    "# Output\n",
    "OUTPUT_FILE_PATH = './'\n",
    "OUTPUT_FILE_NAME = 'processed.pkl'\n",
    "\n",
    "# Constraints\n",
    "MAX_ROWS = 1000\n",
    "# MAX_ROWS = -1 # ALL ROwS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jorge/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/jorge/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jorge/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('words')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from langdetect import DetectorFactory \n",
    "DetectorFactory.seed = 0\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load unprocessed lyrics data\n",
    "df = pd.read_csv('lyrics.csv')\n",
    "if(MAX_ROWS != -1):\n",
    "    df = df.sample(n = MAX_ROWS, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean lyrics data\n",
    "def removeDigits(l):\n",
    "    return \"\".join([letter for letter in l if not letter.isdigit()])\n",
    "    \n",
    "df['lyrics'] = df['lyrics'].apply(lambda l: str(l)\n",
    "                                  .replace('\\n', ' ') # Remove newlines\n",
    "                                  .replace('.', '')   # Remove Punctuations\n",
    "                                  .replace(',', '')   \n",
    "                                  .replace('!', '')   \n",
    "                                  .replace('?', '')\n",
    "                                  .strip()\n",
    "                                  .lower())           # To lower case\n",
    "\n",
    "df['lyrics'] = df['lyrics'].apply(lambda l: removeDigits(l))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Genres\n",
    "def mergeGenre(genre):\n",
    "    if genre == \"Country\" or (genre) == \"Folk\":\n",
    "        return \"Country/Folk\"\n",
    "    if genre == \"Hip-Hop\" or (genre) == \"R&B\":\n",
    "        return \"Hip-Hop/R&B\"\n",
    "    if genre == \"Rock\" or (genre) == \"Metal\":\n",
    "        return \"Rock/Metal\"\n",
    "    return genre\n",
    "    \n",
    "df['genre'] = df['genre'].apply(lambda row: mergeGenre(row))\n",
    "df = df[df['genre'] != 'Other']\n",
    "df = df[df['genre'] != 'Not Available']\n",
    "df = df[df['genre'] != 'Indie']\n",
    "df = df[df['song'].str.contains('remix') == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove song with lyrics below 10\n",
    "df['word_count'] = df['lyrics'].str.split(' ').str.len()\n",
    "df = df[df['word_count'] > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with too many non english words\n",
    "english_vocab = set(w.lower() for w in nltk.corpus.words.words())\n",
    "def isEnglish (l):\n",
    "    retVal = \"failed\"\n",
    "    try:\n",
    "        retVal = detect(l)\n",
    "    except:\n",
    "        print('THESE LYRICS FAILED::', l)\n",
    "    return retVal == 'en'\n",
    "\n",
    "\n",
    "df = df[df['lyrics'].apply(isEnglish)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "sWords = stopwords.words('english')\n",
    "sWords.extend(('got', 'get', 'gets' 'getting', '2X', '2x', 'x2', 'x3', 'x4', 'x2chorus', 'chorus', 'verse', 'bridge', 'd\\xe3', 'n\\xe3', 'm\\xe3', 'the', 'it', 'is', \"it's\", 'are', 'were', 'a', 'an', 'its', 'of', 'for'))\n",
    "\n",
    "def removeStopWords( lyrics ):\n",
    "    tokens = lyrics.split()\n",
    "    return \" \".join([w for w in tokens if not w in sWords])\n",
    "\n",
    "df['lyrics'] = df['lyrics'].apply(removeStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain polarity scores and append to dataframe\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "df['pos_score'] = df['lyrics'].apply(lambda row: sid.polarity_scores(row)['pos'])\n",
    "df['neg_score'] = df['lyrics'].apply(lambda row: sid.polarity_scores(row)['neg'])\n",
    "df['neu_score'] = df['lyrics'].apply(lambda row: sid.polarity_scores(row)['neu'])\n",
    "df['compound_score'] = df['lyrics'].apply(lambda row: sid.polarity_scores(row)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# did it work?\n",
    "#df.to_pickle(\"./processed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n",
      "es\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
